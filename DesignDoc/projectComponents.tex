%!TEX root = ./main.tex
%----------------------------------------------------------------------------------------
%       PROJECT COMPONENTS	
%----------------------------------------------------------------------------------------

\section{Project Components}

This section aims to provide an in depth look at what has been achieved over the life of the
project.

\subsection{Static Analyser}

\subsubsection{Clang Integration}
CAPA utilises the Clang Libtooling library in order to perform semantic static analysis of any C
codebase. The Clang compiler exposes a public library for interfacing with their intermediate
compilation stage representations of the original source. For the purpose of this project as
described in section \ref{integrating_capa} it was decided to use the exposed AST interface in order
to perform the static analysis. The matcher interface provides a declarative API by which the
program searches for regions which satisfy known static requirements. The interface itself is rather
unwieldly to use directly.  \lstinputlisting{./Code/mapMatcher.cpp} As a result I created a matcher
combinator library for simplification purposes.

\subsubsection{ASTMatcher Combinator Library}
In order to simplify the matchers and prevent them from becoming unmanagebly large, I designed a
lambda based combinator library for creating complex ASTMatchers. Utilising C++14 auto lambda return type
declarations I was able to construct a number of higher order combinators which can be combined
together to construct more complex matchers with less ambiguity. A simple example:
\lstinputlisting{./Code/MatcherHelper.h}
This combinator library again is easily extensible and as further needs arose I increased its
complexity and breadth. Ultimately it provides a simpler way of interfacing with the Clang AST
Matcher library through safer higher order functions.
This combinator library would not be possible with earlier versions of C++, as it has a reliance on
auto return types to prevent template instantiation stack errors. The AST Matcher interface heavily
relies on template meta-programming in order to ensure a clean typesafe interface, the combinator
library I designed extends that, yet still maintains complete statically verifiable interfaces that
are type correct.
\lstinputlisting{./Code/nicemap.cpp}
This version is clearly far simpler to understand and to modify, whilst still achieving the same
callback results as the original version. This demonstrates the power of the Matcher Combinator
interface, as well as the ease of use.

\subsubsection{Pattern Recognition}
\paragraph{Matching}
By utilising the OCLint tool the scaffoling around the libtooling had already been provided,
simplifying the interface between pattern matching and reporting. There was still a significant
rewrite of most of the interface, however the heirachy and design philosophy was clear. The actual
matching of potentially parallel sections of code relies on a few assumptions about the nautre of
algorithms which may be efficiently implemented on a GPU.
\begin{itemize}
    \item Little prior data dependency
    \item A large number of elements require processing
    \item Minimal control flow is required
\end{itemize}
Given these assumptions, in combination with the knowledge of problem spaces that the GPU is highly
performant in:
\begin{itemize}
    \item Map Operations
    \item Reduce Operations
    \item Scan (Prefix Network) Operations
    \item Matrix Operations
\end{itemize}
it became clear that identifying components of the codebase that exhibited similarities to these
cases would be important. 

\paragraph{Callback}
Even though the matcher can be highly specific, there is still the requirement of the callback. The
callback is responsible for identifying whether the matched pattern is actually representative of
the expected pattern, or whether it is infact a potential false positive. Additionally the callback
is responsible for logging the detected pattern as well as relevant information, such as the number
of elements being manipulated, for use by the reporter module. This is explained in more detail
in section \ref{caseStudy}.

\subsubsection{Benchmark Integration}
A key aspect of CAPA is the integration of the benchmarking component with the detected outcomes to
provide more detailed performance statistics during the reporting phase.

\paragraph{JSON Parsing}
CAPA relies on performance benchmarks being generated by the benchmarking tool, this reports back
information in a JSON form which is read and parsed by CAPA into a useable form. The JSON for Modern
C++ library was used \cite{JSON}. JSON was chosen as it is a human readable format which is
supported by a large number of tools, additionally the benchmarking libary utilised provided a JSON
exporter, simplifying the integration of the two tools.

\paragraph{Internal Representation}
Internally the benchmarking information relies on this construct:
\lstinputlisting{./Code/benchmarkset.h}
which simply provides a simple concise manner in which to interface with STL containers for the
purpose of passing around the parsed benchmarking information. The BenchmarkSet object is
responsible for handling all requests for benchmark information, including providing theoreticals if
no benchmark JSON file exists. This information is then used by the reporter module to provide the
end user with further information about potential optimisations within their analysed codebase.

\subsubsection{Reporting}
The reporter module is dynamically loaded at runtime to provide the end user with readily swappable
components, this is a continuation of the design decision implemented by the designers of OCLint.
The reporter module is reponsible for accepting all recognised patterns and providing an output.
Reporters are also responsible for utilising performance criteria calculated by the benchmark suite
and integrating this information into the output report. CAPA currently has only one reporter, the
text reporter which provides coloured output for ANSI terminals.

\subsection{Benchmarks}
A key component of this project is the ability of CAPA to provide performance characteristics for a
given system, thus a benchmarking suite was developed to gauge comparitive CPU and GPU performance
for known problem sets.

\subsubsection{Benchmark Structure}
The benchmarking suite is designed using the hayai\cite{hayai} library for benchmark automation,
the hayai library provides a macro interface similar to googleTest, this was used to benchmark both
Host and Device performance.

\subsubsection{Libraries Benchmarked}
Three libraries were benchmarked through this process, in order to emulate industry practice. For
host and device side parallel primitives the CUDA Thrust\cite{thrust} library was used. For Matrix
Multiplication the Eigen\cite{eigen} library was used for the host side implementation, and
CuBLAS\cite{cublas} was used for device side implementation.

\subsubsection{Preperation}
Template metaprogramming was utilised to ensure a generic and extensible testing framework was
generated. A monolithic benchmark object is responsible for setting up and running the individual
operations, which are accessed through a benchmarking fixture via object composition.

\subsubsection{Implementations}
All benchmarks were run with floating point precision, however all benchmarks are templated over
their implementation type, so benchmarks are lower or higher precisions are capable.

Additionally all device benchmarks include onload and offload time for memory management, and no
device benchmarks utilise explicit streaming or pinned memory.

The benchmark code was compiled at with no optimisations and with \lstinline{-fno_vectorize} enabled, to ensure
all host code was purely sequential.
\paragraph{Map}
The map benchmark simply implemented a negation across a number of random elements. This operation
however is accepted as an argument to the map function, thus any unary function or C++ functor
object can be used within the map testing operation.

\subparagraph{Host}
The host map operation is directly implemented by thrust:
\lstinputlisting[linerange={136-139}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}

\subparagraph{Device}
The device map operation is directly implemented by thrust, however the Device Vector is first
intisialised by the Host vector before being operated on.
\lstinputlisting[linerange={141-145}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}


\paragraph{Reduce}
The reduce bencmark is parameterised over a binary operation with a known identity, this is enforced
by the use of template metaprogramming and a simulated closure object via a C++ Functor. The
reduction benchmark traverses the vector searching for the minimum value. Once again though the
reduction operation requires a monoid for implementation, and a C++ functor object can be
constructed which satisfies the monoidal restriction.

\subparagraph{Host}
The host operation relies on thrust for the computation.
\lstinputlisting[linerange={96-100}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}

\subparagraph{Device}
The device operation relies on thrust for the computation.
\lstinputlisting[linerange={102-107}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}


\paragraph{Scan (Prefix Network)}
The scan benchmark is also parameterised over a binary operation with a known identity, again this
enforced by the C++ template engine. The scan benchmark is also traversing the vector searching for
the minimum value, storing all intermediate results. As with the reduction a monoid is required for
processing a Scan operation, in this case once again a C++ functor object can be constructed, so
long as it satisfies the monoidal constraint.

\subparagraph{Host}
The host operation relies on thrust for the computation.
\lstinputlisting[linerange={116-120}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}

\subparagraph{Device}
The device operation relies on thrust for the computation.
\lstinputlisting[linerange={122-127}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}

\paragraph{Dense Matrix Multiplication}
Dense matrix multiplication benchmarks were implemented via Eigen for the host side, and CuBLAS for
the device side. Thrust was used for memory management on the device side. The matrix multiplication
is a square matrix multiply, a square matrix multiply was chosen for simplicity, however this can be
easily changed or extended to provide information about other matrix multiplications.

\subparagraph{Host}
The host operation relies on Eigen for the computation. Eigen provides overloaded operators for
matrix operations.
\lstinputlisting[linerange={169-172}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}

\subparagraph{Device}
The device operation relies on Thrust for memory management and CuBLAS for the actual matrix
multiplication.
\lstinputlisting[linerange={154-162, 173-214}]{/home/james/Projects/CAPA-Benchmarker/benchmark/include/bench.h}

\subsubsection{Typesafe CUDA Primitives} 
Additionally in order to increase code re-use I've attempted to implement the concept of
Type-Classes into CUDA C++. This allows for the single case of higher order functions such as Map,
Reduce and Scan. This implementation utilises template meta-programming and templated type alias's
to produce type safe higher order polymorphism within CUDA compute kernels.
\lstinputlisting{./Code/typeclass.cpp} This code segment demonstrates typeclass instances for
operations over both \textit{Functors} and \textit{BiFunctors}, the \textit{Functor} typeclass is
the alias \lstinline{uCat}, a function which accepts a single input of type \lstinline{T} and
returns a single output of type \lstinline{T}. The second typeclass definition is the
\lstinline{mCat} defition, defining the monoidal typeclass requirement of \textit{mConCat}. This is
any function that accepts 2 inputs of type \lstinline{T} and returns an output of type
\lstinline{T}. These typeclasses are then used to validate the parametric polymorphism of the
\lstinline{biMapKernel}, which implements a polymorphic bimap operation, the key aspect of the
\textit{bifunctor} typeclass, as well as the common map kernel, which is the single requirement of
the \textit{functor} typeclass. This parametric polymorphism provides an easy to use, clear and
concise framework from which to build larger GPU benchmarking routines, by utilising the higher
order nature of the GPU primitives. To summarise this essentially provides a type safe way to write
less code.
