%!TEX root = ./main.tex
%----------------------------------------------------------------------------------------
%       CURRENT POSITION REVIEW	
%----------------------------------------------------------------------------------------

\section{Current Position Review}

This section aims to look forward at what needs to be achieved and how what has been done so far sets up the rest of the project for completion.

\subsection{Incomplete Tasks}
\subsubsection{Identification of more complex parallel patterns} 
At the current point within the project, basic parellel patterns are recognisable within given test code. These patterns are Map operations, Reductions and Scan's. Intermediate complexity matrix operations are considered to be a selection of 2D matrix operations. The most optimisable of these is matrix addition, and subtraction, however multiplication is a readily parallelizable task which must be recognised. The current strategy of identifying parallel patterns by utilising the Clang libtooling matcher library has sufficient flexibility to identify these more complex patterns. Given the success of identifying the basic parallel algorithms, it is expected that this will be achieveable within the timeframe set for the project.

\subsubsection{Identification of complex parallel patterns}
Complex parallel patterns primarily refers to identification of breadth first graph traversal, however it also is in reference to identification of parallel inefficient algorithms and recommending a more efficient parallel implementation, such as depth first search, or certain sorting algorithms. These are significantly more difficult to identify given the large variety of ways in which these algorithms may be written. This introduces significant overhead to both the matcher and the callback, and requires significant effort to develop a generic setup for even one of these problem classes. As such these are considered the most complex patterns for identification, and as such require the largest time investment to bring them up to speed.

\subsubsection{Deisgn and coding of GPU benchmarking suite}
The process has already begun for the production of the GPU benchmarking suite. An object heirachy for generic reporting of statistics has been created, and the initial memory benchmark has been implemented, with performances roughly matching theoretical expectations on the test hardware. The benchmarking suite will include problem classes that the algorithm analyser will be targeting, in order to provide the most relevant information for theoretical performance estimation. As it currently stands, this means the production of basic Map, Reduce and Scan kernels, as well as a basic streaming matrix arithmetic kernels, and potentially an implementation of an efficient breadth first search, if time permits.

\subsubsection{Implementation of theoretical performance analyser}
This is the cumulative goal of the entire FYP, in order to best achieve this goal a combination of the source code analyser and the GPU benchmarker is required; by definition this task is currently incomplete as the two major components that comprise this task are also incomplete. In order to achieve this goal compromises must be made between the depth in whcih both aspects of this project are pursued. In order to provide the best possible outcome it is important that good decision making is undertaken in establishing what aspects of the code analyser and benchmarking suite receive the most attention. The key aim of this task is to provide a report detailing parts of the source code that may see improvements from parallelization. This key aim is enhanced by providing further detail about what sort of potential improvements may be seen in a parallelized implementation. Due to the nature of this relationship it is clear that the code analyser is the \textit{master} and the benchmarks are the \textit{slave} components of the project.

\subsubsection{Presentation Related Items}
These naturally rely on aspects of the project being either completed, or close to completion and as such cannot be completed until far later in the project timeline.

\subsection{Completed Tasks}
\subsubsection{Identification of Simple Parallel Patterns}
This is the initial requirement of the code analyser aspect of this project. Currently simple parallel patterns such as map operations have been successfully completed. This is done utilising the Clang libtooling library, using ASTMatchers and the resulting callback. The current AST Matcher for a map operation is:
\lstinputlisting{./Code/mapMatcher.cpp}
Which identifies the key characteristics of map operations, that being; for loops which increment a loop counter by one with an array assignment which is calculated as a one to one mapping from an input array.

Other matchers for simple parallel patterns are similar in structure to the map matcher, as they are all operations over 1 dimensional arrays. Higher dimension data structures require a different matcher structure to account for their increased complexity.

\subsubsection{Inital Scaffolding of GPU Benchmarking Code}
The current scaffolding of the GPU Benchmarking code provides a benchmarking class which defines the interface by which other aspects of this project must interface with the benchmarking code. Currently the interface is:
\lstinputlisting{./Code/benchmarkScaffold.h}
The current interface design provides a clean API for handling all benchmark requests, as well as providing library users the ability to change configuration information between benchmark operations. The key benefit however is within the restricted interaction beyond initial configuration of the benchmark suite, which provides programs utilising the API a simpler interface from which to work. Internal code within the library is up for change, however as the external API aims to remain constant this should not impact potential library users.

Additionally in order to increase code re-use I've attempted to implement the concept of Type-Classes into CUDA C++. This allows for the single case of higher order functions such as Map, Reduce and Scan. This implementation utilises template meta-programming and templated type alias's to produce type safe higher order polymorphism within CUDA compute kernels.
\lstinputlisting{./Code/typeclass.cpp}
This code segment demonstrates typeclass instances for operations over both \textit{Functors} and \textit{BiFunctors}, the \textit{Functor} typeclass is the alias uCat, a function which accepts a single input of type T and returns a single output of type T. The second typeclass definition is the \textit{mCat} defition, defining the monoidal typeclass requirement of \textit{mConCat}. This is any function that accepts 2 inputs of type T and returns an output of type T. These typeclasses are then used to validate the parametric polymorphism of the \textit{biMapKernel}, which implements a polymorphic bimap operation, the key aspect of the \textit{bifunctor} typeclass, as well as the common map kernel, which is the single requirement of the \textit{functor} typeclass. This parametric polymorphism provides an easy to use, clear and concise framework from which to build larger GPU benchmarking routines, by utilising the higher order nature of the GPU \textit{primatives}. To summarise the category theory, this essentially provides a type safe way to write less code.

\subsubsection{Basic GPU Peak Memory Performance Benchmark}
The current peak memory performance benchmark is an incredibly simple memory test, the base benchmark is merely allocates memory on the device, copies memory from the host to the device, performs a no-op on the device and copies the memory back from the device to the host. This is all timed in order to calculate a peak theoretical memory bandwidth. The benchmark was written before the current version of the benchmark object existed, and as such it does not have any dynamic reponse to changing structure. It is merely a proof of concept for the peak memory performance benchmark.
\lstinputlisting{./Code/memoryBandwidth.cpp}
Even though this code does not interface with the GPU benchmark object it is a trivial transformation to effect that change and bring this inital benchmark into a useable form.

\subsubsection{Scaffolding of Performance Metric Reporting}
By utilising the OCLint tool, the rule and reporter interface has already been written. There are a few alterations that still need to be undertaken, as the nature of the reports is somewhat different between the original intention of OCLint, and what I am doing, however the overall scaffolding and relationship between analysis and report is finished, and quite robust.

\subsubsection{Capable of Analysing Arbitrarily Large C Codebases}
As the static code analyser uses the Clang libtooling, if the codebase being run on is capable of being built by clang, then it is possible for the codebase to be analysed CAPA. This is due to the heavy lifting being done by the clang compiler, and the tool hooking in only at the AST stage per compilation unit.


