%!TEX root = ./main.tex
%---------------------------------------------------------------------------------------- PROJECT
%DESCRIPTION
%----------------------------------------------------------------------------------------

\section{Project Description} 
My final year project aimed to create a set of static code/compiler analytics tools to help determine
which algorithms within a code-base may be easily parallelized. The specific intention of it is to provide 
users with a report describing which parts of their code-base may see a potential speed-up from
redeveloping them as CUDA (GPU) \cite{cuda} kernels. In order to achieve this both benchmarking and theoretical
analysis was required, as well as static analysis of the C description of the algorithm itself. My
final project utilised a combined strategy of static AST analysis, via a hook into the Clang
Libtooling, as well as integration with a benchmarking suite I created that utilised real high
performance libraries for both Host and Device code. The use case of this software is for developers
working primarily in modelling and mathematically intensive areas, as these tend to provide
significant opportunity to provide improvement. The expectation of potential users is that they will
note that the report alerts them to potential speedups, and then use the performance metrics to
determine whether or not to hire a specialised engineer to redesign the relevant components of their
system.

\subsection{Compiler Analytics} 
Given a C description of an algorithm, a report is to be generated,
highlighting areas within the code that may see a potential speed-up based on matching to known GPU
performant patterns. In order to achieve this, a static analysis methodology was invoked. Direct
source code analysis is incredibly difficult, and suffers from a number of drawbacks, including the
difficulty to parse C and (notoriously difficult) C++. Considering the time constraints involved it
was decided that the analysis tool would hook into the Clang Libtooling  library, which provides access
to the Clang Abstract Syntax Tree, giving a semi-syntax invariant canvas from which to identify
relevant parallel patterns.

Given the difficulty of setting up a generic build environment for the Clang tooling, I decided to
fork a project named OCLint \cite{oclint}, a C, C++ and Obj-C static analysis tool that I had worked with earlier.
This tool provides a light framework around the Clang tooling, however most importantly it provides
sophisticated build scripts which work on a variety of operating systems and distributions.

\subsubsection{OCLint Modification} 
Forking the OCLint project, which is licensed under a modified
BSD license has saved significant time and effort from being wasted developing a generic build
system around the Clang tooling. The OCLint software provides a direct method for interacting with
the Clang AST by exposing the Clang Libtooling headers. This increased flexibility has in turn
allowed for more time to be spent developing methods to identify parallel patterns within the
generated AST. All changes to the OCLint software are unrelated to its original
intention and design, and as such no pull requests were lodged, and no modifications I
have written have moved upstream. As I have substantially re-engineered and re-purposed the OCLint
software I have elected to give it a new name, the C Algorithm Parallelisation Analyser (CAPA).

\subsection{GPU Benchmarking}
In order to best provide theoretical performance improvements of
algorithms within a codebase, an analysis of the current hardware available is significantly
important. As such rather than just provide purely theoretical numbers, part of this project
involved developing a simple set of GPU benchmarks which seek to show performance metrics for the
identified patterns within the code analyser. This in effect means that reports generated by the
analytics tool may contain specific information pertaining to the hardware available on the current
build and test system. In order to achieve the best outcome, CUDA was decided on as the framework
for development.

\subsubsection{Benchmarks}
GPUs are exceptionally good at high throughput calculations, one
particular example is SIMD, meaning \emph{Same Instruction Multiple Data}. The performance of GPUs
and the algorithms they are particularly useful for is well under continual research, however
general problem classes that GPUs are able to solve efficiently are well understood. These problem
sets include algorithms that can be described by any of the following:

\begin{itemize} 
    \item Map 
    \item Fold/Reduce 
    \item Scan/Prefix Network 
    \item Matrix Operations
\end{itemize}

The actual speed improvements derived from redeveloping serial code to take advantage of the
massively parallel compute power of a GPU differs between each of these operations, however many
serial algorithms have equivalent or more performant alternate parallel implementations. As such
this project involves developing a small set of benchmarks for GPUs that determine their
performance in each of these categories. In order to satisfy time constraints and recognise real
world concerns, I elected to use existing optimised libraries for the individual components of the
benchmarking. I relied on the Eigen Library \cite{eigen} for host side matrix operations. On the
device side I relied on a combination of the thrust template library \cite{thrust} in combination
with CuBLAS \cite{cublas}

\subsubsection{CUDA} 
CUDA is Nvidia's proprietary library and toolchain for developing parallel
software. There are 2 main frameworks in the GPU programming space, CUDA and OpenCL. Whilst OpenCL
is a FOSS platform, the development tools are severely lacking in comparison to the CUDA toolkit, and
as such it was an easy decision to follow through with the CUDA. This however has limited the
performance metrics to only comparisons involving CUDA enabled graphics cards. This is not too great
a concern however, as the benchmarking module is highly extensible and as a result can easily
integrate with a variety of backends, including OpenCL or OpenMP.
